{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM-digit recognition day 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=load_digits()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "info",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'info'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6208d269f320>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: info"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "\n",
      "[0 1 2 ... 8 9 8]\n",
      "\n",
      "(1797, 8, 8)\n",
      "\n",
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(data.data)\n",
    "print()\n",
    "print(data.target)\n",
    "print()\n",
    "print(data.images.shape)\n",
    "print()\n",
    "dataimagelength=len(data.images)\n",
    "print(dataimagelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAALrUlEQVR4nO3d/2td9R3H8ddraYvfqpHpRIyYCbMgQpMiZVLQrVWpU6o/7IcWFCob3Q+bWDYQ3S+j/4C6H4ZQqlawVrTaMmRzFjSIsLm1NZ21qUNLxKxqFK1VByvqez/cU8litpzE8zm5yfv5gEvvvbne9/smvu45595zztsRIQAL27fmugEA5RF0IAGCDiRA0IEECDqQAEEHEuiKoNtea/t122/YvrtwrYdsj9s+VLLOhHoX237B9ojt12zfWbjeabb/avtgVW9LyXpVzR7br9h+pnStqt6o7VdtD9veV7hWr+1dto9Uf8OrCtZaVr2mU5cTtjc38uQRMacXST2S3pR0qaQlkg5KurxgvaslrZB0qKXXd6GkFdX1pZL+Ufj1WdJZ1fXFkl6W9P3Cr/GXkh6T9ExLv9NRSee1VOsRST+tri+R1NtS3R5J70q6pInn64Yl+kpJb0TE0Yg4KelxSTeXKhYRL0r6sNTzT1HvnYg4UF3/RNKIpIsK1ouI+LS6ubi6FNsrynafpBslbStVY67YPludBcODkhQRJyPieEvl10h6MyLeauLJuiHoF0l6e8LtMRUMwlyy3S9pUJ2lbMk6PbaHJY1L2hsRJevdL+kuSV8WrDFZSHrO9n7bmwrWuVTS+5IerjZNttk+s2C9idZL2tnUk3VD0D3FfQtuv1zbZ0l6StLmiDhRslZEfBERA5L6JK20fUWJOrZvkjQeEftLPP//sSoiVki6QdLPbV9dqM4idTbzHoiIQUmfSSr6GZIk2V4iaZ2kJ5t6zm4I+pikiyfc7pN0bI56KcL2YnVCviMinm6rbrWaOSRpbaESqyStsz2qzibXatuPFqr1lYg4Vv07Lmm3Opt/JYxJGpuwRrRLneCXdoOkAxHxXlNP2A1B/5uk79n+bvVOtl7S7+e4p8bYtjrbeCMRcW8L9c633VtdP13StZKOlKgVEfdERF9E9Kvzd3s+Im4tUesU22faXnrquqTrJRX5BiUi3pX0tu1l1V1rJB0uUWuSDWpwtV3qrJrMqYj43PYvJP1JnU8aH4qI10rVs71T0g8knWd7TNJvIuLBUvXUWerdJunVartZkn4dEX8oVO9CSY/Y7lHnjfyJiGjla6+WXCBpd+f9U4skPRYRzxasd4ekHdVC6Kik2wvWku0zJF0n6WeNPm/1UT6ABawbVt0BFEbQgQQIOpAAQQcSIOhAAl0V9MK7M85ZLepRb67rdVXQJbX5y2z1D0c96s1lvW4LOoACiuwwY5u9cBp02WWXzfi/+fjjj3XOOefMqt6iRTPfYfKjjz7SueeeO6t6hw+3sVdpHhHxtQPFCPo8MDQ01Gq93t7eVusNDAy0Wm+hmyrorLoDCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUigVtDbHJkEoHnTBr06yeDv1DkF7eWSNti+vHRjAJpTZ4ne6sgkAM2rE/Q0I5OAharOYUq1RiZVB8q3fcwugBrqBL3WyKSI2Cppq8TRa0C3qbPqvqBHJgEZTLtEb3tkEoDm1TqVSDUnrNSsMACFsWcckABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEEZj57B7r55naP0r3mmmtarbdly5ZW66E8luhAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IoM5Ipodsj9s+1EZDAJpXZ4m+XdLawn0AKGjaoEfEi5I+bKEXAIWwjQ4k0NhhqsxeA7pXY0Fn9hrQvVh1BxKo8/XaTkl/lrTM9pjtn5RvC0CT6gxZ3NBGIwDKYdUdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACjmh+t/SFvq/78PBwq/WWL1/ear3BwcFW67X9+1zoIsKT72OJDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQTqnBzyYtsv2B6x/ZrtO9toDEBz6pzX/XNJv4qIA7aXStpve29EHC7cG4CG1Jm99k5EHKiufyJpRNJFpRsD0JwZbaPb7pc0KOnlEs0AKKP2SCbbZ0l6StLmiDgxxc+ZvQZ0qVpBt71YnZDviIinp3oMs9eA7lXnU3dLelDSSETcW74lAE2rs42+StJtklbbHq4uPyrcF4AG1Zm99pKkr52aBsD8wZ5xQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSYPbaLIyOjrZa7/jx463WGxgYaLUemsXsNSApgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiRQ5yywp9n+q+2D1ey1LW00BqA5dc7r/m9JqyPi0+r87i/Z/mNE/KVwbwAaUucssCHp0+rm4uqyoA9aARaaWtvotntsD0sal7Q3Ipi9BswjtYIeEV9ExICkPkkrbV8x+TG2N9neZ3tf000C+GZm9Kl7RByXNCRp7RQ/2xoRV0bElQ31BqAhdT51P992b3X9dEnXSjpSujEAzanzqfuFkh6x3aPOG8MTEfFM2bYANKnOp+5/lzTYQi8ACmHPOCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCTB7bRbanoU2PDzcar09e/Ys6Hptz85rG7PXgKQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kEDtoFdDHF6xzYkhgXlmJkv0OyWNlGoEQDl1RzL1SbpR0ray7QAooe4S/X5Jd0n6smAvAAqpM6nlJknjEbF/mscxew3oUnWW6KskrbM9KulxSattPzr5QcxeA7rXtEGPiHsioi8i+iWtl/R8RNxavDMAjeF7dCCBOkMWvxIRQ+qMTQYwj7BEBxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQALPXZqHtWWjLly9vtd7Bgwdbrdf26xscHGy1Xtv/vzB7DUiKoAMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwnUOmdcdarnTyR9IelzTukMzC8zOTnkDyPig2KdACiGVXcggbpBD0nP2d5ve1PJhgA0r+6q+6qIOGb7O5L22j4SES9OfED1BsCbANCFai3RI+JY9e+4pN2SVk7xGGavAV2qzjTVM20vPXVd0vWSDpVuDEBz6qy6XyBpt+1Tj38sIp4t2hWARk0b9Ig4Kqndc/0AaBRfrwEJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSGAmx6Ojsn379lbr3Xfffa3WGx0dbbVef39/q/VuueWWVuu1PXttKizRgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kECtoNvutb3L9hHbI7avKt0YgObU3df9t5KejYgf214i6YyCPQFo2LRBt322pKslbZSkiDgp6WTZtgA0qc6q+6WS3pf0sO1XbG+rBjn8F9ubbO+zva/xLgF8I3WCvkjSCkkPRMSgpM8k3T35QYxkArpXnaCPSRqLiJer27vUCT6AeWLaoEfEu5Letr2sumuNpMNFuwLQqLqfut8haUf1iftRSbeXawlA02oFPSKGJbHtDcxT7BkHJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABZq/NQtuz19qeTbZx48ZW6w0NDbVab8+ePa3W6wYs0YEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQSmDbrtZbaHJ1xO2N7cRnMAmjHtLrAR8bqkAUmy3SPpn5J2F+4LQINmuuq+RtKbEfFWiWYAlDHToK+XtLNEIwDKqR306pzu6yQ9+T9+zuw1oEvN5DDVGyQdiIj3pvphRGyVtFWSbEcDvQFoyExW3TeI1XZgXqoVdNtnSLpO0tNl2wFQQt2RTP+S9O3CvQAohD3jgAQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBBzR/PEntt+XNJtj1s+T9EHD7XRDLepRr616l0TE+ZPvLBL02bK9LyKuXGi1qEe9ua7HqjuQAEEHEui2oG9doLWoR705rddV2+gAyui2JTqAAgg6kABBBxIg6EACBB1I4D9eopfa9NSAOgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., 12., 13.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  5., 16.,  8.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 16.,  3.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 14., 13.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 15., 12.,  7.,  2.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 16., 13., 16.,  3.,  0.],\n",
       "       [ 0.,  0.,  7., 16., 11., 15.,  8.,  0.],\n",
       "       [ 0.,  0.,  1.,  9., 15., 11.,  3.,  0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=6\n",
    "import matplotlib.pyplot as plt\n",
    "plt.gray()\n",
    "plt.matshow(data.images[n])\n",
    "plt.show()\n",
    "\n",
    "data.images[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=data.images.reshape(dataimagelength,-1)\n",
    "y=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROHAN\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='poly', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model=SVC(kernel=\"poly\",degree=3,C=1.0)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEsUlEQVR4nO3dIY9cZRSA4XNJDQGaBoOtAQMJq1H7OzBdgQFViev8CfwmCHC0An7HIDCoIjAYZgMYEjIIICFk0ybQvffd4XnkHXFOsvvmm9xM8i3H43GAnpe2XgC4njghSpwQJU6IEidEiROixAlR4jwRy7K8vizLF8uy/LIsy3fLsry/9U78N3e2XoAX5pOZ+XVm3piZs5n5clmWr4/H4zfbrsW/tfiF0O23LMsrM/PjzLxzPB6//fPZpzPz/fF4/HjT5fjXfK09DW/NzG9/hfmnr2fm7Y324QUQ52l4dWau/vHsamZe22AXXhBxnoafZ+buP57dnZmfNtiFF0Scp+HbmbmzLMubf3v27sx4GXSLeSF0IpZl+XxmjjPzwfzxtvarmXnP29rby8l5Oj6amZdn5oeZ+WxmPhTm7ebkhCgnJ0SJE6LECVHihKjn/fD9JN8WHQ6HVeftdrvVZl1eXq426/z8fLVZjx8/Xm3WBpbrHjo5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcEPW86xhO0sXFxarznjx5stqsR48erTZrzasf1pw1s/7/yHWcnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTojKXMfw9OnT1WateT3CzMyDBw9Wm7Xb7VabdTgcVpu13+9Xm1Xh5IQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCEqc1fKvXv3tl7hxlxcXGy9wo045b9ZgZMTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUZnrGPb7/dYrQIqTE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVGZ6xjOzs62XuHGXF1drTbrcDisNmvNKzR2u91qsyqcnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTohajsfjsz5/5oe31fn5+dYr3Jj79+9vvcKNuLy83HqFm7Rc99DJCVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtT/8q6Uw+Gw6ryHDx+uNmu/3682a837S87OzlabtQF3pcBtIk6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6Iet51DMBGnJwQJU6IEidEiROixAlR4oSo3wEwAYCCbjwSggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=10\n",
    "result=model.predict(data.images[n].reshape((1,-1)))\n",
    "plt.imshow(data.images[n],cmap=plt.cm.gray_r , interpolation=\"nearest\")\n",
    "print(result)\n",
    "print()\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"%i\"%result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score for our model is 98.61111111111111%\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"accuracy_score for our model is {}%\".format(accuracy_score(y_test,y_pred)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
